---
title: "Introducción a la estadística"
subtitle: "![](logo.jpg){width=2in}"
author: "Dra. Stephanie Hereira Pacheco"
institute: "CTCB, UATx"
date: 06-03-2024
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    nature:
      ratio: '16:9'
---
```{r jquery, echo=FALSE}
htmltools::tagList(rmarkdown::html_dependency_jquery())
```


```{r xaringan-themer, include=FALSE, warning=FALSE, eval=FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#5E2129",
  code_highlight_color = "#E3906F", 
  code_inline_color = "#0E2B54",
    text_font_size = "1.3rem",

)
```

```{r xaringanExtra-clipboard, echo=FALSE}
htmltools::tagList(
  xaringanExtra::use_clipboard(
    button_text = "<i class=\"fa fa-clipboard\"></i>",
    success_text = "<i class=\"fa fa-check\" style=\"color: #90BE6D\"></i>",
  ),
  rmarkdown::html_dependency_font_awesome()
  )

xaringanExtra::use_logo(
  image_url = "https://www.ciisder.mx/images/logos/logo_uatx_2019.png",
  position = xaringanExtra::css_position(top = "1em", right = "1em")
)

xaringanExtra::use_tile_view()

xaringanExtra::use_share_again()


```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
```



# Contenido

+ Pruebas paramétricas y supuestos estadísticos.

    - t de Student

+ Pruebas no paramétricas y supuestos estadísticos.

    - U de Mann Whitney

    - Prueba de Wilcoxon.
    
    
---
## Pruebas paramétricas y supuestos estadísticos

Se conoce como estadística paramétrica a aquella que se basa en el muestreo de una población con una distribución conocida y con  parámetros fijos. 

Los supuestos de las pruebas paramétricas en general son:

- Distribución conocida (**normal**): visual y pruebas numéricas.

- Homocedasticidad: visual y pruebas numéricas.

- Otros: tamaño de la muestra, variables cuantitativas o continuas, outliers, aleatoriedad, independencia de las observaciones, linealidad. 

.

.center[*** Cada tipo de prueba paramétrica tiene sus propios supuestos***]
---

### Distribución normal: métodos visuales

.pull-left[
```{r, echo=FALSE}
set.seed(123)

```

```{r, fig.align='center', fig.height=6}
data_normal<- rnorm(200)
hist(data_normal, col='steelblue', main='Normal')
```
]
.pull-right[
```{r, echo=FALSE}
set.seed(1254)
```

```{r, fig.align='center', fig.height=6}
data_no_normal<- rexp(100, rate=3)
hist(data_no_normal, col='red', main='No normal')
```
]
---
### Distribución normal: métodos visuales

.pull-left[
```{r, echo=FALSE}
set.seed(123)

```

```{r, fig.align='center', fig.height=6}
plot(density(data_normal), main="Normal")
```
]
.pull-right[

```{r, fig.align='center', fig.height=6}
plot(density(data_no_normal), main="No Normal")
```
]

---
### Distribución normal: métodos visuales

.pull-left[
```{r, echo=FALSE}
set.seed(123)

```

```{r, fig.align='center', fig.height=6}
qqnorm(data_normal)
qqline(data_normal)
```
]
.pull-right[

```{r, fig.align='center', fig.height=6}
qqnorm(data_no_normal)
qqline(data_no_normal)
```
]
---
### Distribución normal: métodos numéricos

.pull-left[
```{r, echo=FALSE}
set.seed(124)

```

```{r, fig.align='center', fig.height=6, message=FALSE, warning=FALSE}
shapiro.test(data_normal)
```


```{r, fig.align='center', fig.height=6, message=FALSE, warning=FALSE}
ks.test(data_normal, "pnorm")
```
]
.pull-right[

```{r, fig.align='center', fig.height=6}
shapiro.test(data_no_normal)

```

```{r, fig.align='center', fig.height=6, message=FALSE, warning=FALSE}
ks.test(data_no_normal, "pnorm")
```

]
---
## Probando heterocedasticidad
- Métodos visuales = Pruebas estadísticas de comparación y modelos lineales
.pull-left[
```{r, echo=FALSE}
data("ToothGrowth")
data("iris")
```


```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
data("ToothGrowth")
boxplot(len ~ supp, data=ToothGrowth, col=c("red", "blue"), main="Dientes")
```

]
.pull-right[

```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
data("iris")
boxplot(Petal.Width ~ Species, data=iris, col=c("pink", "purple", "cyan"), main="Flores")
```

]
---
## Probando heterocedasticidad
- Métodos visuales = Pruebas estadísticas de comparación y modelos lineales
.pull-left[
```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
aggregate(len ~ supp, data = ToothGrowth, var)
```
Ratio
```{r}
68.32 /  43.63
```

]
.pull-right[
```{r, fig.align='center', fig.height=5,fig.width=4, message=FALSE, warning=FALSE}
aggregate(Petal.Width ~ Species, data = iris, var)

```
Ratio
```{r}
r1<-0.03910612 / 0.01110612 #versicolor vs setosa
r2<-0.07543265 / 0.01110612 #virginca vs setosa
r3<-0.07543264 / 0.03910612 #virginica vs versicolor
cbind(r1,r2,r3)
```
]
---
### Probando heterocedasticidad
.pull-left[
```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
m1<-lm(len ~ supp, data=ToothGrowth)
par(mfrow = c(1, 2))
plot(m1, which=c(1,3))
```

]
.pull-right[

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
m2<-lm(Petal.Width ~ Species, data=iris)
par(mfrow = c(1, 2))
plot(m2, which=c(1,3))
```

]

---
### Probando heterocedasticidad


.pull-left[
Prueba para dos niveles = F

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}

var.test(len ~ supp, data = ToothGrowth) 

```
]


.pull-right[

```{r, fig.align='center', fig.height=5,fig.width=8, message=FALSE, warning=FALSE}
lmtest::bptest(m2) #sobre un modelo

library(car)
leveneTest(m2)
```

```{r, eval=FALSE}
?fligner.test
```


]

>- Otras pruebas: Prueba de Goldfeld-Quand, White, entre otras.

---
# PRUEBAS PARAMÉTRICAS


|VENTAJAS    | DESVENTAJAS     | 
|-------------------|-------|
| - Sensibles a rasgos de los datos recolectados  | - Más complicadas de calcular | 
| - Estimaciones probabilísticas más exactas       |- Solo se pueden aplicar si se cumplen sus supuestos   | 
| - Tienen una mayor eficiencia y poder estadístico      | - Los datos que se pueden observar son limitados| 

---
# PRUEBAS PARAMÉTRICAS


|TIPO    |   PRUEBA     | 
|:-------------------:|:-------:|
| Comparación de 2 grupos	  |   t de Student/Welch  | 
| Comparación de >2 grupos       | Anova   | 
| Correlación de dos variables     | Coeficiente de Pearson| 
| Variables cualitativas     | Prueba de Z| 

---
# t de Student
- Desarrollada por William Sealy Gosset. La prueba t permite comparar las medias de una muestra con la media teórica de una población, o comparar dos poblaciones. 

- Una de las características de la prueba de student, es que permite la hipótesis alternativa de ver si dos medias son diferentes o si, una media es mayor, o menor que otra. 

- Esta prueba tiene variantes dependiendo de nuestros datos.

- Para ser utilizada es necesario que se cumplan los siguientes supuestos:
>- Muestreo aleatorio
>- Los datos y errores deben tener una distribución normal 
>- Cuando se comparan dos distribuciones las varianzas deben ser iguales (σ1=σ2) y/o homogéneas.

---
# t de Student una muestra


En la prueba t de Student para una muestra, se usa la siguiente fórmula:


$$t=\frac{\bar{x}-\mu}{s/\sqrt{n}}$$
Dónde $t$ es el estadístico, $\bar{x}$ es la media muestral, $s$ es la desviación estándar muestral,  $n$ es el tamaño de la muestra y $\mu$ es la media verdadera de la población. 

El estadístico $t$ posee un valor de p asociado dependiendo de los grados de libertad de la prueba. 

Mide qué tan inusual es la media de la muestra observada de la media de la muestra hipotética. Lo hace midiendo qué tan lejos está la media de la muestra observada de la media de la población hipotética en términos de errores estándar.

---
### Ejemplo de una muestra

.pull-left[

```{r, warning=FALSE, message=FALSE}
data<- data.frame(Congelador=1:10,
                  Temperatura=c(-2.14,-0.8,
                                -2.75,-2.58,   
                                -2.26,-2.46,
                                -1.33,-2.85,
                                -0.93,-2.01))
shapiro.test(data$Temperatura)$p.value
```

Manualmente 
```{r, warning=FALSE, message=FALSE}
prom = mean(data$Temperatura); desves = sd(data$Temperatura); sn = sqrt(nrow(data));mu = 0
t=(prom-mu)/(desves/sn)
t;pt(t, df=9)
```
]

.pull-rigth[
Con R
```{r}
t.test(data$Temperatura, mu = 0, alternative = "less")
```
]

---

## t de Student para medidas pareadas

En la prueba t de Student para medidas pareadas se usa la siguiente fórmula:

$$t=\frac{\bar{x}_{d}-\mu_{d}}{s_{d}/\sqrt{n}}$$
Dónde $t$ es el estadístico, $\bar{x_{d}}$ es la media muestral de la diferencia de las medidas, $s_{d}$ es la desviación estándar muestral, $n$ es el tamaño de la muestra y $\mu_{d}$ es la diferencia de medias de mis grupos. 

- Data ejemplo:

```{r}
data_pareada<- data.frame(Pan=1:10,
                         Temp_pre=c(20.83,19.72,19.64,20.09,22.25,
                                   20.83,21.31,22.50,21.17,19.57),
                         Temp_post=c(100.87,98.58,109.09,121.83,122.78,
                                     111.41,103.96,121.81,127.85,115.17))

data_pareada$Diferencia<- data_pareada$Temp_post - data_pareada$Temp_pre
                                
```

---
## Ejemplo muestras pareadas
```{r, echo=FALSE}
knitr::kable(data_pareada, align = "c")
```

---
# Ejemplo muestras pareadas

.pull-left[

```{r, warning=FALSE, message=FALSE}
shapiro.test(data_pareada$Diferencia)
```

Manualmente 
```{r, warning=FALSE, message=FALSE}
prom = mean(data_pareada$Diferenci); desves = sd(data_pareada$Diferenci); sn = sqrt(nrow(data_pareada));mu = 0
t=(prom-mu)/(desves/sn)
t;pt(t, df=9, lower.tail = FALSE)
```
]

.pull-rigth[
Con R
```{r}
t.test(data_pareada$Temp_post, data_pareada$Temp_pre, mu = 0, alternative = "greater", paired = TRUE)
```
]

---

# t de Student para dos grupos

En la prueba t de Student para dos grupós se usa la siguiente fórmula:

$$t_{obs}=\frac{\bar{x_{1}}-\bar{x_{2}}-\Delta}{\sqrt{s^2/n_{1}+s^2/n_{2}}}$$

Dónde $t_{obs}$ es el estadístico, $\bar{x_{1,2}}$ son los promedios de los grupos y $\Delta$ es el promedio teórico de la distribución nula de la diferencia de promedios (usualmente se usa 0), el $s^2$ viene dado por:
$$s^2=\frac{\Sigma{(x_{1}-\bar{x_{1}})^2}-\Sigma{(x_{2}-\bar{x_{2}})^2}}{n_{1}+n_{2}-2} = \frac{s^2_{1}(n_{1}-1)-s^2_{2}(n_{2}-1)}{n_{1}+n_{2}-2}$$ 

En este caso los grados de libertad se calculan :
$$df = (n_{1}-1)+(n_{2}-1)=n_{1}+n_{2}-2$$
---
# t de Student para dos grupos

- Debemos tener en cuenta si hay dependencia o no de los grupos y si la varianza es igual y/o homogénea. 

- Cuando los grupos son independientes, se supone que proceden de diferentes poblaciones que tienen la misma varianza. 

- La t de muestras independientes es una medida de la diferencia de las medias de los dos grupos. 

- La distribución de la que se muestrea la diferencia de medias no es de una sola población sino de la combinación de las dos poblaciones. 

-Por ejemplo, tengo una población con promedio de 10 y otra de 7, varianzas de 4 y 4, entonces mi combinación tendrá un promedio de 3 (diferencia) y varianza de 8. 


---
## Ejemplo para dos grupos
.pull-left[
```{r}
freidora<- data.frame(
  Oster1=c(4.72,7.40,3.50,3.85,4.47,
           4.09,6.34,3.30,7.13,4.99),
  Oster2=c(9.19,11.44,9.64,12.09,10.80,
           12.71,10.04,9.06,6.31,9.44))
ro1<- freidora$Oster1-mean(freidora$Oster1)
ro2<- freidora$Oster2-mean(freidora$Oster2)

shapiro.test(c(ro1,ro2))
```

]
.pull-right[
```{r, echo=FALSE}
knitr::kable(freidora, align = "c", format = "pipe", padding = 0)
```
]

---
# Ejemplo para dos grupos

.pull-left[
Manualmente 
```{r, warning=FALSE, message=FALSE}
prom1 = mean(freidora$Oster1)
prom2=mean(freidora$Oster2)

s=((var(freidora$Oster1)*9)+(var(freidora$Oster2)*9))/(10+10-2)
t=(prom1-prom2-0)/(sqrt(s/10+s/10))
t; pt(-6.8527, df=18, lower.tail=TRUE)+pt(6.8527, df=18, lower.tail=FALSE)
```
]

.pull-rigth[
Con R
```{r}
t.test(freidora$Oster1, freidora$Oster2, mu=0, paired=FALSE, alternative="two.sided", var.equal=TRUE)
```
]

---

# Prueba de Welch

.pull-left[

Para los casos donde no se cumplen que las varianzas sean iguales u homogéneas.

$$t_{obs}=\frac{\bar{x_{1}}-\bar{x_{2}}-\Delta}{\sqrt{s_{1}^2/n_{1}+s_{2}^2/n_{2}}}$$

Los grados de libertad se calculan:

$$df =\frac{(s_{1}^2/n_{1}+s_{2}^2/n_{2})^2}{s_{1}^4/(n_{1}-1)+s_{2}^4/(n_{2}-1)}$$
]
.pull-right[
```{r}
t.test(freidora$Oster1, freidora$Oster2, mu=0, paired=FALSE, alternative="two.sided", var.equal=FALSE)
```
]
---
## Pruebas no paramétricas y supuestos estadísticos

- Las pruebas no paramétricas no requieren que conozcamos la distribución de nuestros datos ni parámetros de la población de estudio como su media o varianza poblacional.

- Las pruebas no paramétricas nos permiten analizar
datos en escala nominal u ordinal y en su mayoría los resultados se derivan a partir de procedimientos de ordenación y recuento, por lo que su base lógica es de fácil comprensión. 

- Cuando trabajamos con muestras pequeñas (n < 10) en
las que se desconoce si es válido suponer la normalidad de los datos, conviene utilizar pruebas no paramétricas

- Pocos supuestos: aleatoriedad e independencia.

---
# PRUEBAS NO PARAMÉTRICAS


|VENTAJAS    | DESVENTAJAS     | 
|-------------------|-------|
| - Mayor aplicabilidad | - Eficiencia estadística menor
| - Se pueden usar variables ordinales     |- Poder estadísitico menor   | 
| - Son más fáciles de calcular     | - No se pueden evaluar interacciones| 

---
# PRUEBAS NO PARAMÉTRICAS


|TIPO    |   PRUEBA     | 
|:-------------------:|:-------:|
| Comparación de 2 grupos	  |   Wilcoxon/U Mann Withney | 
| Comparación de >2 grupos       | Kruskal-wallis/Friedman  | 
| Correlación de dos variables     | Coeficiente de Spearman| 
| Variables cualitativas     | Chi-cuadrada/Fisher| 

---
# U Mann Whitney

- Este	estadístico,	introducido	simultáneamente	por	Mann	y	Whitney	en	1947,	se	utiliza	para	contrastar	si	dos	muestras,	extraídas	independientemente,	proceden	de	la	misma	población, no admite medidas repetidas.

- Compara	las	diferencias	entre	dos	medianas,	por	lo	que	se	basa	en	rangos	en	lugar	de	en	los	parámetros	de	la	muestra	(media,	varianza).

- Requisitos: variable cuantitativa, independencia y aleatoriedad.

- Establece que existen diferencias entre las medianas  de dos grupos sin suponer cuál de las dos es mayor o menor que la otra. 
---
# U Mann Whitney

- Se ordenan los datos (juntando los grupos) en orden creciente. El rango de cada dato será el número de orden que le corresponde.

- Se suman los rangos de cada uno de los grupos y se calcula la suma de los rangos de cada grupo $(W_{1},W_{2}$).

- Se escoge el menor y considerando los df se puede usar una tablar de valores críticos para evaluar la significancia. 


---
## U Mann Whitney - Ejemplo
.pull-left[
```{r}
data_u<- data.frame(Control=c(12, 22, 38, 42, 50),
                    Tratamiento=c(14, 25, 40, 44, 48))

```

```{r}
knitr::kable(data_u, align = "c")
```
]

.pull-right[
```{r, echo=FALSE}
dat<- data.frame(Tipo= c("C", "E","C", "E","C", "E", "C", "E", "E", "C"), Valor=c(12,14,22,25,38,40,42,44,48,50))
knitr::kable(dat, align = "c")

```

]
---
```{r, echo=FALSE}
dat2<-data.frame(C=12, E=14, C=22, E=25, C=38, E=40, C=42, E=44, E=48, C=50, check.names = F)
```
```{r, echo=FALSE}
knitr::kable(dat2, align = "c")
```
Para la condición de control, tomamos el número total de valores de la condición experimental que son más pequeños que cada valor de la condición de control. Hay 0 valores (12), 1 que es más pequeño que el segundo valor más pequeño (22), 2 que son más pequeños que el tercer valor más pequeño (38), 3 que son menores de 42, y 5 que son menores de 50 para un total de 11.

Para la condición del tratamiento, tomamos el número de valores que son más pequeños que cada valor de la condición experimental. Hay 1 valor de condición de control más pequeño que el valor de condición experimental más pequeño (14), 2 que son más pequeños que 25, 3 que son más pequeños que 40, 4 que son más pequeños que 44 y también 4 que son más pequeños que 48 para un Total de 14. 

Tomamos el valor de U como el menor que sería 11.
---
# U Mann Whitney - Ejemplo
En R
```{r}
wilcox.test(data_u$Control, data_u$Tratamiento, paired = FALSE)
```


---
# Prueba de Wilcoxon para dos muestras dependientes

- Esta es la opción no paramétrica para la prueba t de Student cuando los errores no se distribuyen de manera normal y se tiene una muestra o dos muestras apareadas. 

- El estadístico W se calcula obteniendo las diferencias de los valores, ordenando de menor a mayor el valor absouto de las diferencias las diferencias y asignando un rango, en caso de empates se obtiene la media de los rangos y se asigna el mismo rango a las dos observaciones.

- Funciona de la misma manera que la anterior pero es más potente porque tiene en cuenta la magnitud de los rangos de las diferencias. Es decir, una pequeña diferencia negativa o positiva significa menos o más en el cálculo de la estadística de prueba que una gran diferencia negativa o positiva.

---

# Prueba de Wilcoxon 

1. Arreglar las observaciones pareadas y obtener las diferencias de cada pareja.
2. Arreglar las diferencias en función de rangos como valores absolutos, sin importar el signo, pero de manera que los rangos conserven el signo correspondiente a la
diferencia.
3. Obtener la sumatoria de los rangos en valores absolutos por signos.
4. Si se trata de muestras pequeñas, comparar el valor obtenido con los valores críticos de la tabla de Wilcoxon.
5. Distribuir las muestras mayores que 25 bajo la curva normal y, por tanto, calcular el valor Z.
6. Decidir si se acepta o rechaza la hipótesis

---

## Prueba Wilcoxon - ejemplo
.pull-left[
```{r}
data_w<- data.frame(Observ=c(1:11),
                    Antes=c(1,8,0,0,1,3,3,3,5,6,5),
                    Despues=c(3,5,-2,-1,1,-5,-7,-362,-1,0,-10))
data_w$Diferencia<- data_w$Antes-data_w$Despues

```
]
.pull-right[
```{r,echo=FALSE, warning=FALSE,message=FALSE}
library(kableExtra)
knitr::kable(data_w, align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
]

---

.pull-left[
```{r, echo=FALSE}
knitr::kable(data_w %>% dplyr::arrange(-Diferencia), align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
]
.pull-rigth[
```{r, echo=FALSE}
dato<- data_w %>% dplyr::arrange(-Diferencia) %>% mutate(Rango=c(10,9,8,7,5.5,5.5,4,2.5,1,0,2.5)) 
knitr::kable(dato, align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```

]

---
```{r,echo=FALSE}
dato<- data_w %>% dplyr::arrange(-Diferencia) %>% mutate(Rango=c(10,9,8,7,5.5,5.5,4,2.5,1,0,2.5)) %>% mutate(Signo=c("+", "+", "+","+", "+", "+","+","+","+","=","-"), Rango_Signo=paste0(Signo,Rango)) 
knitr::kable(dato, align = "c") %>%
  kable_classic(full_width = F, html_font = "Cambria")
```
---

# Wilcoxon -ejemplo
.pull-left[
```{r,echo=TRUE}
T_pos = 10+9+8+7+5.5+5.5+4+2.5+1
T_neg = 2.5

T_pos; T_neg
```
```{r}
Two_tailed_W = max(T_pos,T_neg)
Two_tailed_W
```
]

.pull-right[
En R
```{r, warning=FALSE, message=FALSE}
wilcox.test(data_w$Antes, data_w$Despues, paired = TRUE)
```

]

---
# Ejemplo aplicado

```{r}
Grupo1 <- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)
Grupo2 <- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4) 
my_data <- data.frame( 
                group = rep(c("G1", "G2"), each = 9),
                weight = c(Grupo1,  Grupo2)
                )

```
¿Hay diferencias entre estos dos grupos?

--


.pull-left[
```{r}
with(my_data, shapiro.test(weight[group == "G1"]))
```
]
.pull-rigth[
```{r}
#Prueba de normalidad
with(my_data, shapiro.test(weight[group == "G2"])) 
```
]
---
# Ejemplo aplicado

```{r}
Grupo1 <- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)
Grupo2 <- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4) 
my_data <- data.frame( 
                group = rep(c("G1", "G2"), each = 9),
                weight = c(Grupo1,  Grupo2)
                )

```
¿Hay diferencias entre estos dos grupos?
--
```{r}
var.test(weight ~ group, data = my_data)
```

---
# Ejemplo aplicado

```{r}
Grupo1 <- c(38.9, 61.2, 73.3, 21.8, 63.4, 64.6, 48.4, 48.8, 48.5)
Grupo2 <- c(67.8, 60, 63.4, 76, 89.4, 73.3, 67.3, 61.3, 62.4) 
my_data <- data.frame( 
                group = rep(c("G1", "G2"), each = 9),
                weight = c(Grupo1,  Grupo2)
                )

```
¿Hay diferencias entre estos dos grupos?
--
```{r}
t.test(Grupo1, Grupo2, var.equal = TRUE)
```
---
# RESUMEN

|ESTADÍSTICOS PARAMÉTRICOS       |  ESTADÍSTICOS NO PARAMÉTRICOS     | 
  |:-------------------|:-------|
  | Se conoce la población, paramétros y distribución  |   No se conoce la población, parámetros y distribución | 
  | Supuestos basados en población       | Sin supuestos sobre la población  | 
  | Aplicable para variables continuas     | Aplicable para continuas y muchos tipos de discretas| 
  | Mayor poder estadísitco     | Menor poder estadístico| 


---

## Referencias y material suplementario

- [Advanced Statistics I 2021 Edition](https://bookdown.org/danbarch/psy_207_advanced_stats_I/differences-between-two-things.html#sign-binomial-test)

- [Pruebas paramétricas y no paramétricas](https://enviromigration.files.wordpress.com/2016/04/pruebas-paramc3a9tricas-y-no-parametricas.pdf)

- [Estadística paramétrica y no paramétrica](https://rstudio-pubs-static.s3.amazonaws.com/724751_c45a17f9e45f464c93e94f3fb0c6d340.html#16)

- [Prácticos de bioestadística 2](https://derek-corcoran-barrios.github.io/AyduantiaStats/_book/t-student.html)

---
# Tarea

- Escoge un conjunto de datos de R, visto anteriormente o datos propios.
- Escoge las variable de respuestas y grupos a evaluar (verifica que sean dos grupos si son más filtrar).
- Prueba los supuestos de los estadísticos paramétricos
- Dependiendo de tus resultados aplica el estadístico adecuado en cada caso. 
- Sube tu tarea a más tardar el 29 de marzo en el classroom.
- Puede ser un script de R o un documento en word pero pega el código y resultados.



---
class: inverse, center, middle

# MUCHAS GRACIAS.